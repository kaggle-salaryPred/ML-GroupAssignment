{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('traindataset.csv',memory_map=True) #importing cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"Housing Situation\",\"Satisfation with employer\",\n",
    "                    \"Gender\",\"Country\",\"Profession\",\"University Degree\",\"Hair Color\"]\n",
    "conti_cols = [\"Year of Record\",\"Crime Level in the City of Employement\",\n",
    "              \"Work Experience in Current Job [years]\",\"Age\",\"Size of City\",\"Wears Glasses\",\n",
    "              \"Body Height [cm]\",\"Yearly Income in addition to Salary (e.g. Rental Income)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function takes a string column name and returns a list\n",
    "#containing indices of dataframe that have outliers in that column\n",
    "#Refer: hs://towardsdatascience.com/5-ways-to-detect-outliers-that-every-data-scientist-should-know-python-code-70a54335a623\n",
    "def OutlierByColumn(colname):\n",
    "    rows = data.shape[0]\n",
    "    col_std = np.std(data[colname])\n",
    "    col_mean = np.mean(data[colname])\n",
    "    anomaly_cut_off = col_std * 3\n",
    "    lower_limit  = col_mean - anomaly_cut_off \n",
    "    upper_limit = col_mean + anomaly_cut_off\n",
    "    anomalies_indices = []\n",
    "    for i in range(rows):\n",
    "        ele = data[colname][i]\n",
    "        if ele > upper_limit or ele < lower_limit:\n",
    "            anomalies_indices.append(i)\n",
    "    return anomalies_indices        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import EllipticEnvelope\n",
    "#https://chrisalbon.com/machine_learning/preprocessing_structured_data/detecting_outliers/\n",
    "def outlierdetect(colname):\n",
    "    outlier_detector = EllipticEnvelope(contamination=.52)\n",
    "    val = data[colname].values\n",
    "    # Fit detector\n",
    "    outlier_detector.fit(val.reshape(-1, 1))\n",
    "    # Predict outliers\n",
    "    res = outlier_detector.predict(val.reshape(-1, 1))\n",
    "    return np.where(res == -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = outlierdetect('Work Experience in Current Job [years]')\n",
    "arr2 = outlierdetect('Age')\n",
    "arr3 = outlierdetect('Body Height [cm]')\n",
    "#arr4 = outlierdetect('Yearly Income in addition to Salary (e.g. Rental Income)')\n",
    "arr5 = outlierdetect('Size of City')\n",
    "arr6 = outlierdetect('Total Yearly Income [EUR]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr4 = OutlierByColumn('Yearly Income in addition to Salary (e.g. Rental Income)')#oulierdetect() was not working for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(991712, 18)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape #checking no of rows and no of columns for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "944985"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Union of all lists \n",
    "union_index = np.union1d(arr1,arr2)\n",
    "union_index = np.union1d(union_index,arr3)\n",
    "union_index = np.union1d(union_index,arr4)\n",
    "union_index = np.union1d(union_index,arr5)\n",
    "union_index = np.union1d(union_index,arr6)\n",
    "len(union_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(union_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read somewhere that binary encoders take less space\n",
    "import category_encoders as ce\n",
    "encoder = ce.BinaryEncoder(categorical_cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding categorical columns\n",
    "encoded = encoder.fit_transform(data[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Total Yearly Income [EUR]'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining encoded columns with continuous columns\n",
    "encoded = encoded.join(data[conti_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46727, 47)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= encoded.values\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.feature_selection import SelectKBest\\nfrom sklearn.feature_selection import f_regression\\nfrom sklearn.feature_selection import chi2\\nskb = SelectKBest(f_regression, k=47)         HERE K DENOTES NUMBER OF FEATURES I TRIED FROM 10 TILL 47, \\n                                              THE MODEL GOT BETTER WITH MORE FEATURES, THE BEST WHEN ALL ARE THERE\\nskb.fit(x, y)\\nx = skb.transform(x)'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I was trying to select K-best features but, as it turns out, it is best to include all features. \n",
    "'''from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import chi2\n",
    "skb = SelectKBest(f_regression, k=47)         HERE K DENOTES NUMBER OF FEATURES I TRIED FROM 10 TILL 47, \n",
    "                                              THE MODEL GOT BETTER WITH MORE FEATURES, THE BEST WHEN ALL ARE THERE\n",
    "skb.fit(x, y)\n",
    "x = skb.transform(x)''' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling https://medium.com/coinmonks/machine-learning-tutorial-1-preprocessing-d90198e37577\n",
    "from sklearn import preprocessing\n",
    "scaler_model = preprocessing.StandardScaler().fit(x)\n",
    "x = scaler_model.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating data into train and test\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3806.733315882951"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ExtraTreesRegressor\n",
    "#This will take some time to execute \n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "gbr = ExtraTreesRegressor(n_estimators=25,max_features=\"sqrt\")\n",
    "gbr.fit(xtrain.astype(int),ytrain.astype(int))\n",
    "ypred = gbr.predict(xtest.astype(int))\n",
    "np.sqrt(metrics.mean_squared_error(ytest, ypred))#Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1314.12,  8535.96,  3628.64,  3166.4 , 14070.32,  2470.88,\n",
       "        7891.52,  1332.  ,  7708.  ,  5980.72])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1657.12,  2541.81,  3222.58,  1263.43, 14365.6 ,  1655.97,\n",
       "        6069.35,  1332.77,  7708.66,  5835.44])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
